<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Manipulation | EECS 106A Project Showcase</title>
<meta name="keywords" content="">
<meta name="description" content="UC Berkeley EECS 106A Introduction to Robotics - Student Project Showcase">
<meta name="author" content="EECS 106A Students">
<link rel="canonical" href="https://berkeleydrone.github.io/tags/manipulation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.588ba43c1c9efa82d61d120adfb15e94e7678a83f3c9f673f6f045563e60cc4b.css" integrity="sha256-WIukPBye&#43;oLWHRIK37FelOdnioPzyfZz9vBFVj5gzEs=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://berkeleydrone.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://berkeleydrone.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://berkeleydrone.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://berkeleydrone.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://berkeleydrone.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://berkeleydrone.github.io/tags/manipulation/index.xml" title="rss">
<link rel="alternate" hreflang="en" href="https://berkeleydrone.github.io/tags/manipulation/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="https://berkeleydrone.github.io/tags/manipulation/">
  <meta property="og:site_name" content="EECS 106A Project Showcase">
  <meta property="og:title" content="Manipulation">
  <meta property="og:description" content="UC Berkeley EECS 106A Introduction to Robotics - Student Project Showcase">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Manipulation">
<meta name="twitter:description" content="UC Berkeley EECS 106A Introduction to Robotics - Student Project Showcase">

</head>

<body class="list" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://berkeleydrone.github.io/" accesskey="h" title="EECS 106A Project Showcase (Alt + H)">EECS 106A Project Showcase</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://berkeleydrone.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#overview" title="Overview">
                    <span>Overview</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#architecture" title="Architecture">
                    <span>Architecture</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#implementation" title="Hardware">
                    <span>Hardware</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#documentation" title="Software">
                    <span>Software</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#demo" title="Demo">
                    <span>Demo</span>
                </a>
            </li>
            <li>
                <a href="https://berkeleydrone.github.io/#about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="https://berkeleydrone.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="https://berkeleydrone.github.io/tags/">Tags</a></div>
  <h1>
    Manipulation
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">UR5e Cube Grasp Project
    </h2>
  </header>
  <div class="entry-content">
    <p> ðŸ¤– UR5e Cube Grasp Robotic Manipulation with Visual Feedback
ðŸ“‹ Project Overview This project demonstrates autonomous robotic manipulation using the UR5e robotic arm combined with an Intel RealSense D435 depth camera for visual feedback. The system can identify, locate, and grasp colored cubes placed on a tabletop.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-10 00:00:00 +0000 UTC'>December 10, 2024</span>&nbsp;Â·&nbsp;<span>2 min</span>&nbsp;Â·&nbsp;<span>EECS 106A Students</span></footer>
  <a class="entry-link" aria-label="post link to UR5e Cube Grasp Project" href="https://berkeleydrone.github.io/posts/hello-world/"></a>
</article>
    </main>
    <footer style="
  background: #F8F9FA;
  border-top: 1px solid #E4E6EB;
  padding: 48px 24px;
  margin-top: -30px;
  width: 100vw;
  position: relative;
  left: 50%;
  right: 50%;
  margin-left: -50vw;
  margin-right: -50vw;
  z-index: 10;
">
  <div style="
    max-width: 1200px;
    margin: 0 auto;
    text-align: center;
  ">
    <div style="color: #8A8D91; font-size: 0.875rem; margin-bottom: 8px;">
      Â© 2025 UC Berkeley Â· EECS 106/206A Final Project
    </div>
    <div style="color: #BCC0C4; font-size: 0.8rem;">
      Built by <a href="https://dongc1.github.io/" target="_blank" style="color: #0668E1; text-decoration: none; font-weight: 500; transition: color 0.2s ease;" onmouseover="this.style.color='#5C7CFA'" onmouseout="this.style.color='#0668E1'">dongc1</a>
    </div>
  </div>
</footer>

<button class="back-to-top" id="backToTop">
  <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
    <path d="M12 4l-8 8h5v8h6v-8h5l-8-8z"/>
  </svg>
</button>

<script>
(function() {
  const backToTop = document.getElementById('backToTop');
  
  window.addEventListener('scroll', function() {
    if (window.scrollY > 300) {
      backToTop.classList.add('show');
    } else {
      backToTop.classList.remove('show');
    }
  });
  
  backToTop.addEventListener('click', function() {
    window.scrollTo({
      top: 0,
      behavior: 'smooth'
    });
  });
})();


const videoData = [
  {
    id: 'LBzI1GDyFOo',
    badge: 'Stage 1',
    title: 'Target Acquisition',
    desc: 'Initial marker detection and approach with aggressive gains for fast response. The drone quickly identifies the ArUco marker and begins its approach maneuver.',
    phase: 'Acquisition',
    control: 'High Gain PID',
    goal: 'Fast Detection'
  },
  {
    id: 'jF4QE1jB2JU',
    badge: 'Stage 2',
    title: 'Overshoot / Transient',
    desc: 'Tuning PID gains to reduce overshoot and oscillation during transient phase. This stage focuses on dampening the initial aggressive response.',
    phase: 'Transient',
    control: 'Dampened PID',
    goal: 'Reduce Oscillation'
  },
  {
    id: 'G2pCyJFHyck',
    badge: 'Stage 3',
    title: 'Target Tracking',
    desc: 'Stable hovering with smooth tracking. Low gains for minimal jitter. The drone maintains steady position relative to the marker.',
    phase: 'Tracking',
    control: 'Low Gain PID',
    goal: 'Smooth Tracking'
  },
  {
    id: 'WFyeybVqn1Q',
    badge: 'Stage 4',
    title: 'No Latency Tracking',
    desc: 'Optimized system with minimal latency for real-time responsive control. Final tuned parameters for competition-ready performance.',
    phase: 'Optimized',
    control: 'Tuned PID',
    goal: 'Zero Latency'
  }
];

function openModal(index) {
  const modal = document.getElementById('videoModal');
  const video = document.getElementById('modalVideo');
  const data = videoData[index];
  
  video.src = 'https://www.youtube.com/embed/' + data.id + '?autoplay=1';
  document.getElementById('modalBadge').textContent = data.badge;
  document.getElementById('modalTitle').textContent = data.title;
  document.getElementById('modalDesc').textContent = data.desc;
  document.getElementById('modalPhase').textContent = data.phase;
  document.getElementById('modalControl').textContent = data.control;
  document.getElementById('modalGoal').textContent = data.goal;
  
  modal.classList.add('active');
  document.body.style.overflow = 'hidden';
}

function closeModal(event) {
  const modal = document.getElementById('videoModal');
  const video = document.getElementById('modalVideo');
  
  video.src = '';
  modal.classList.remove('active');
  document.body.style.overflow = '';
}

document.addEventListener('keydown', function(e) {
  if (e.key === 'Escape') {
    closeModal();
    closeDocModal();
  }
});


const docData = [
  {
    tag: 'Hardware',
    title: 'Drone Frame & Components',
    bg: 'https://berkeleydrone.github.io/images/docs/drone_parts.png',
    content: `
      <h3>Overview</h3>
      <p>In this project, the Jetson Xavier is used as the main compute unit to run the code stack, including sensor drivers, control, perception, and planning modules. The communication is established between the Jetson Xavier (the brain) and the flight controller (the muscle).</p>
      
      <h3>Frame and Fasteners</h3>
      <table>
        <tr><th>Component</th><th>Type</th></tr>
        <tr><td>Frame</td><td>A2RL X DCL SPEC FRAME</td></tr>
        <tr><td>Battery Strap</td><td>Gemfan Kevlar Strap</td></tr>
        <tr><td>XT30 Connectors</td><td>XT30 Male and Female Pairs</td></tr>
      </table>
      
      <h3>Electronics</h3>
      <table>
        <tr><th>Component</th><th>Type</th></tr>
        <tr><td>Motors</td><td>XNOVA Black Thunder 2207 2100KV</td></tr>
        <tr><td>ESC</td><td>Foxeer Reaper F4 128K 65A BL32 4in1</td></tr>
        <tr><td>Flight Controller</td><td>Foxeer H7 MPU6000 FC</td></tr>
        <tr><td>VTX Antenna</td><td>Foxeer 5.8G Micro Lollipop</td></tr>
        <tr><td>VTX Camera</td><td>HDZERO Nano 90</td></tr>
        <tr><td>VTX</td><td>HDZERO Race 3 VTX</td></tr>
        <tr><td>Receiver</td><td>IRC Ghost Atto</td></tr>
      </table>
      
      <h3>RC Controller</h3>
      <table>
        <tr><th>Component</th><th>Type</th></tr>
        <tr><td>Controller</td><td>Radiomaster Zorro 4in1</td></tr>
        <tr><td>Transmitter Module</td><td>Ghost Module</td></tr>
        <tr><td>Propellers</td><td>MCK 51466 V2 (5 inch)</td></tr>
      </table>
      
      <img src="https://berkeleydrone.github.io/images/docs/drone_parts.png" alt="Drone Parts">
      <p class="img-caption">Figure 1: Parts and sensors used in the project</p>
      
      <img src="https://berkeleydrone.github.io/images/docs/Drone_frame_image.png" alt="Drone CAD">
      <p class="img-caption">Figure 2: CAD design of the drone parts</p>
    `
  },
  {
    tag: 'Calibration',
    title: 'Sensor Calibration',
    bg: 'https://berkeleydrone.github.io/images/docs/calibrated_images.png',
    content: `
      <h3>Overview</h3>
      <p>Sensor calibration is an essential step for any real-world robotics platform to work properly and effectively. This is particularly true for custom-built platforms, such as the drone used in this project.</p>
      
      <h3>IMU Calibration</h3>
      <p>For the IMU calibration, we recorded an 11-hour static ROS 2 bag to estimate intrinsic noise characteristics and long-term drift. The bag was converted to ROS 1 format using the rosbags package to enable offline calibration with the Allan Variance toolkit.</p>
      <ul>
        <li>Initial IMU data rate: ~30 Hz</li>
        <li>Current maximum rate: 90 Hz</li>
        <li>Target rate: 200+ Hz for state estimation</li>
      </ul>
      
      <h3>Camera Calibration</h3>
      <p>Camera intrinsic calibration and IMUâ€“camera extrinsic calibration were performed using the Kalibr toolbox (ROS1). Multiple calibration bags were collected while moving the drone and checkerboard, producing accurate estimates of:</p>
      <ul>
        <li>Focal lengths and principal points</li>
        <li>Distortion parameters</li>
        <li>Rigid transformation T<sub>IC</sub> between IMU and camera frames</li>
      </ul>
      
      <img src="https://berkeleydrone.github.io/images/docs/calibrated_images.png" alt="Calibrated Images">
      <p class="img-caption">Figure 1: Demonstration of calibrated images</p>
      
      <img src="https://berkeleydrone.github.io/images/docs/accel_noise.png" alt="Accelerometer Noise">
      <p class="img-caption">Figure 2: Calibration results - accelerometer</p>
      
      <img src="https://berkeleydrone.github.io/images/docs/gyro_noise.png" alt="Gyroscope Noise">
      <p class="img-caption">Figure 3: Calibration results - gyroscope</p>
      
      <img src="https://berkeleydrone.github.io/images/docs/summary_noise.png" alt="Noise Summary">
      <p class="img-caption">Figure 4: Calibration results - summary</p>
    `
  },
  {
    tag: 'Perception',
    title: 'Perception Module',
    bg: 'https://berkeleydrone.github.io/images/docs/pipeline_diagram.png',
    content: `
      <h3>Overview</h3>
      <p>The Perception Module is responsible for processing raw camera images to detect and localize visual targets (ArUco markers and gates) in the drone's environment. It acts as the sensory processing layer that bridges Hardware (camera sensors) and Planning (high-level decision making).</p>
      
      <h3>ArUco Detector Node</h3>
      <p>Detects ArUco markers in camera images and publishes their pixel coordinates and 3D pose in the camera frame.</p>
      <ul>
        <li><strong>Dictionary:</strong> DICT_4X4_50 (50 unique 4Ã—4 markers)</li>
        <li><strong>Marker Size:</strong> 0.15 m (configurable)</li>
        <li><strong>Pose Estimation:</strong> cv2.solvePnP() with IPPE_SQUARE</li>
      </ul>
      
      <h3>Gate Detector Node</h3>
      <p>Detects racing gates using color-based segmentation (LAB color space) and contour detection with visual tracking (CSRT tracker).</p>
      <ul>
        <li><strong>Color Space:</strong> LAB for perceptually uniform segmentation</li>
        <li><strong>Tracking:</strong> CSRT (Discriminative Correlation Filter)</li>
        <li><strong>Gate Size:</strong> 1.4m Ã— 1.4m</li>
      </ul>
      
      <h3>Data Flow</h3>
      <img src="https://berkeleydrone.github.io/images/docs/pipeline_diagram.png" alt="Pipeline Diagram">
      <p class="img-caption">ArUco Marker tracking pipeline diagram</p>
      
      <h3>Key Topics</h3>
      <table>
        <tr><th>Topic</th><th>Type</th><th>Description</th></tr>
        <tr><td>/aruco_detector/marker_pixel</td><td>PointStamped</td><td>Marker center in pixels</td></tr>
        <tr><td>/aruco_detector/marker_pose</td><td>PoseStamped</td><td>Marker 3D pose</td></tr>
        <tr><td>/aruco_detector/detected</td><td>Bool</td><td>Detection status</td></tr>
      </table>
    `
  },
  {
    tag: 'Planning',
    title: 'Planning Module',
    bg: 'https://berkeleydrone.github.io/images/docs/Drone_frame_image.png',
    content: `
      <h3>Overview</h3>
      <p>The Planning Module is responsible for generating desired drone poses (position, orientation, and velocity setpoints) based on pre-planned trajectories, sensor feedback, or real-time perception data.</p>
      
      <h3>Planning Strategies</h3>
      <ul>
        <li><strong>Autonomous Planner:</strong> Follows pre-recorded waypoint trajectories from CSV files using KD-tree nearest-neighbor search</li>
        <li><strong>ArUco Tracker Planner:</strong> Dynamically tracks ArUco markers, computing desired poses to keep markers centered</li>
        <li><strong>Sequential Planner:</strong> Simple waypoint-by-waypoint traversal without localization feedback</li>
        <li><strong>Manual Planner:</strong> Records pilot-controlled flight paths for later replay</li>
      </ul>
      
      <h3>ArUco Tracker Control Law</h3>
      <p>The tracker computes velocity commands to center the marker:</p>
      <ul>
        <li><code>error_x = marker_pixel.x - (image_width / 2)</code></li>
        <li><code>vel_y = -gain_x Ã— error_x</code> (lateral velocity)</li>
        <li><code>vel_x = gain_z Ã— distance_error</code> (forward velocity)</li>
      </ul>
      
      <h3>Configuration Parameters</h3>
      <table>
        <tr><th>Parameter</th><th>Default</th><th>Description</th></tr>
        <tr><td>image_width/height</td><td>1920Ã—1080</td><td>Camera resolution</td></tr>
        <tr><td>gain_x, gain_y</td><td>0.002</td><td>Pixel to velocity gain</td></tr>
        <tr><td>gain_z</td><td>0.5</td><td>Distance to velocity gain</td></tr>
        <tr><td>target_distance</td><td>1.5 m</td><td>Desired distance to marker</td></tr>
        <tr><td>max_vel_xy</td><td>0.5 m/s</td><td>Max lateral velocity</td></tr>
      </table>
    `
  },
  {
    tag: 'Control',
    title: 'Control Module',
    bg: 'https://berkeleydrone.github.io/images/docs/accel_noise.png',
    content: `
      <h3>Overview</h3>
      <p>The Control Module is responsible for converting high-level desired poses and velocities (from the Planning Module) into low-level RC commands that drive the drone's motors via the flight controller.</p>
      
      <h3>Control Strategies</h3>
      <ul>
        <li><strong>Autonomous Control Node:</strong> Full 6-DOF position and attitude control using cascade PID with localization feedback</li>
        <li><strong>Velocity Control Node:</strong> Simplified velocity-to-RC mapping for visual servoing (no localization required)</li>
        <li><strong>Manual Control Node:</strong> Pass-through relay for human pilot RC commands</li>
      </ul>
      
      <h3>PID Configuration</h3>
      <table>
        <tr><th>Axis</th><th>KP</th><th>KI</th><th>KD</th></tr>
        <tr><td>X-axis</td><td>8.0</td><td>0.0</td><td>5.0</td></tr>
        <tr><td>Y-axis</td><td>8.0</td><td>0.0</td><td>5.0</td></tr>
        <tr><td>Z-axis (altitude)</td><td>20.0</td><td>0.0</td><td>5.0</td></tr>
        <tr><td>Yaw</td><td>1.0</td><td>0.0</td><td>0.0</td></tr>
      </table>
      
      <h3>Control Law</h3>
      <p><strong>Outer Loop (Position Control):</strong></p>
      <ul>
        <li><code>pos_error = desired_pos - current_pos</code></li>
        <li><code>r_ddot_des = KP Ã— pos_error + KD Ã— vel_error</code></li>
      </ul>
      
      <p><strong>Inner Loop (Attitude):</strong></p>
      <ul>
        <li><code>phi_des (roll) = (r_ddot_des_x Ã— sin(yaw) - r_ddot_des_y Ã— cos(yaw)) / g</code></li>
        <li><code>theta_des (pitch) = (r_ddot_des_x Ã— cos(yaw) + r_ddot_des_y Ã— sin(yaw)) / g</code></li>
      </ul>
      
      <h3>PWM Channel Mapping</h3>
      <table>
        <tr><th>Channel</th><th>Function</th><th>Range</th></tr>
        <tr><td>1</td><td>Roll</td><td>1000-2000 PWM</td></tr>
        <tr><td>2</td><td>Pitch</td><td>1000-2000 PWM</td></tr>
        <tr><td>3</td><td>Throttle</td><td>1000-2000 PWM</td></tr>
        <tr><td>4</td><td>Yaw</td><td>1000-2000 PWM</td></tr>
        <tr><td>5</td><td>AUX1 (ARM)</td><td>1000 = armed</td></tr>
      </table>
    `
  },
  {
    tag: 'Workflow',
    title: 'Development Workflow',
    bg: 'https://berkeleydrone.github.io/images/docs/gyro_noise.png',
    content: `
      <h3>Overview</h3>
      <p>This document summarizes the development workflow in three areas: hardware setup and testing, sensor calibration, and task implementation.</p>
      
      <h3>Step 1: Hardware Setup and Testing</h3>
      <p>We assembled and bench-tested the aircraft powertrain, flight controller, radios, and data links.</p>
      <ul>
        <li><strong>Visual inspection:</strong> Frame integrity, motor/prop orientation, connector seating</li>
        <li><strong>Power checks:</strong> Battery voltage, PDU rail voltages</li>
        <li><strong>ESC/motor bench test:</strong> Spin each motor at low throttle (props removed)</li>
        <li><strong>Telemetry and RC link test:</strong> Verify RC receiver channels and ground station connectivity</li>
      </ul>
      
      <h3>Step 2: Sensor Calibration</h3>
      <p>We calibrated IMU, magnetometer, barometer, and camera to ensure reliable state estimation.</p>
      <ul>
        <li><strong>IMU calibration:</strong> Static bias, temperature compensation tables</li>
        <li><strong>Magnetometer:</strong> Full rotation / figure-eight motions for hard/soft iron corrections</li>
        <li><strong>Camera:</strong> OpenCV calibrateCamera for intrinsics and distortion</li>
      </ul>
      
      <h3>Step 3: Task Implementation</h3>
      <p>With hardware validated and sensors calibrated, we implemented mission-level tasks.</p>
      <ul>
        <li><strong>State estimation integration:</strong> EKF/UKF with sensor streams</li>
        <li><strong>Control loop tuning:</strong> PID/P gains using step responses</li>
        <li><strong>Mission scripting:</strong> YAML/JSON waypoint definitions</li>
        <li><strong>Testing progression:</strong> SITL â†’ bench tests â†’ tethered flights â†’ real flights</li>
      </ul>
      
      <img src="https://berkeleydrone.github.io/images/docs/pipeline_diagram.png" alt="Pipeline Diagram">
      <p class="img-caption">ArUco Marker tracking pipeline diagram</p>
      
      <h3>Recommended Tools</h3>
      <table>
        <tr><th>Tool</th><th>Purpose</th></tr>
        <tr><td>Gazebo</td><td>Physics simulation with wind and sensor noise</td></tr>
        <tr><td>MAVProxy / QGroundControl</td><td>Ground station monitoring</td></tr>
        <tr><td>rosbag</td><td>Data recording and replay</td></tr>
        <tr><td>OpenCV / NumPy / SciPy</td><td>Calibration and image processing</td></tr>
      </table>
    `
  }
];

function openDocModal(index) {
  const modal = document.getElementById('docModal');
  const data = docData[index];
  
  document.getElementById('docModalBg').style.backgroundImage = 'url(' + data.bg + ')';
  document.getElementById('docModalTag').textContent = data.tag;
  document.getElementById('docModalTitle').textContent = data.title;
  document.getElementById('docModalContent').innerHTML = data.content;
  
  modal.classList.add('active');
  document.body.style.overflow = 'hidden';
}

function closeDocModal(event) {
  const modal = document.getElementById('docModal');
  modal.classList.remove('active');
  document.body.style.overflow = '';
}
</script>
</body>

</html>
